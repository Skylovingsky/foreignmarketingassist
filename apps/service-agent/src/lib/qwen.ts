import OpenAI from 'openai';
import crypto from 'crypto';
import type { ChatRequest, ChatResponse, AgentMessage } from '@trade-assistant/dto';

export class QwenClient {
  private client?: OpenAI;
  private model: string = 'qwen-plus';

  private useMockMode: boolean;

  constructor() {
    const apiKey = process.env.DASHSCOPE_API_KEY;
    const baseURL = process.env.DASHSCOPE_BASE_URL || 'https://dashscope-intl.aliyuncs.com/compatible-mode/v1';
    
    // è°ƒè¯•æ—¥å¿—
    console.log('ğŸ”‘ Debug - API Key exists:', !!apiKey);
    console.log('ğŸ”‘ Debug - API Key starts with:', apiKey ? apiKey.substring(0, 10) + '...' : 'null');
    
    // æ£€æŸ¥æ˜¯å¦ä½¿ç”¨æ¼”ç¤ºæ¨¡å¼
    this.useMockMode = !apiKey || apiKey === 'sk-demo-key-placeholder';
    
    console.log('ğŸ­ Debug - Use mock mode:', this.useMockMode);
    
    if (!this.useMockMode) {
      console.log('ğŸš€ Initializing real Qwen client with API key');
      console.log('ğŸ”§ Debug - Base URL:', baseURL);
      this.client = new OpenAI({
        apiKey,
        baseURL,
        defaultHeaders: {
          'User-Agent': 'trade-assistant/1.0.0',
        },
      });
    } else {
      console.log('ğŸ­ Running in mock mode - using simulated AI responses');
    }
  }

  async chat(request: ChatRequest): Promise<ChatResponse> {
    if (this.useMockMode) {
      return this.getMockResponse(request);
    }

    // Try direct HTTP client first as workaround
    try {
      return await this.chatDirect(request);
    } catch (directError) {
      console.warn('ğŸ”„ Direct HTTP failed, trying OpenAI SDK:', directError);
      
      try {
        if (!this.client) {
          throw new Error('OpenAI client not initialized');
        }

        const messages = request.messages.map(msg => ({
          role: msg.role as 'user' | 'assistant' | 'system',
          content: msg.content,
        }));

        console.log('ğŸ” Debug - Making API call with model:', this.model);
        console.log('ğŸ” Debug - Messages count:', messages.length);

        const response = await this.client.chat.completions.create({
          model: this.model,
          messages,
          temperature: request.temperature || 0.7,
          max_tokens: request.maxTokens || 2000,
          stream: false,
        });

        console.log('âœ… Debug - API call successful');

        const choice = response.choices[0];
        const message: AgentMessage = {
          id: crypto.randomUUID(),
          role: 'assistant',
          content: choice.message.content || '',
          timestamp: new Date().toISOString(),
        };

        return {
          message,
          usage: {
            promptTokens: response.usage?.prompt_tokens || 0,
            completionTokens: response.usage?.completion_tokens || 0,
            totalTokens: response.usage?.total_tokens || 0,
          },
        };
      } catch (error) {
        console.error('ğŸš¨ Qwen API error:', error);
        console.error('ğŸš¨ Error details:', JSON.stringify(error, null, 2));
        if (error && typeof error === 'object' && 'status' in error) {
          console.error('ğŸš¨ HTTP Status:', error.status);
        }
        throw new Error(`AI service error: ${error instanceof Error ? error.message : 'Unknown error'}`);
      }
    }
  }

  private async chatDirect(request: ChatRequest): Promise<ChatResponse> {
    const apiKey = process.env.DASHSCOPE_API_KEY;
    const baseURL = process.env.DASHSCOPE_BASE_URL || 'https://dashscope.aliyuncs.com/compatible-mode/v1';
    
    const messages = request.messages.map(msg => ({
      role: msg.role,
      content: msg.content,
    }));

    console.log('ğŸ”¥ Direct HTTP call to DashScope API');

    const response = await fetch(`${baseURL}/chat/completions`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: this.model,
        messages,
        temperature: request.temperature || 0.7,
        max_tokens: request.maxTokens || 2000,
        stream: false,
      }),
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error('ğŸš¨ Direct API Error:', response.status, errorText);
      throw new Error(`API Error: ${response.status} ${errorText}`);
    }

    const data = await response.json();
    console.log('âœ… Direct HTTP call successful');

    const choice = data.choices[0];
    const message: AgentMessage = {
      id: crypto.randomUUID(),
      role: 'assistant',
      content: choice.message.content || '',
      timestamp: new Date().toISOString(),
    };

    return {
      message,
      usage: {
        promptTokens: data.usage?.prompt_tokens || 0,
        completionTokens: data.usage?.completion_tokens || 0,
        totalTokens: data.usage?.total_tokens || 0,
      },
    };
  }

  async *streamChat(request: ChatRequest): AsyncGenerator<any, void, unknown> {
    if (this.useMockMode) {
      yield* this.getMockStreamResponse(request);
      return;
    }

    try {
      if (!this.client) {
        throw new Error('OpenAI client not initialized');
      }

      const messages = request.messages.map(msg => ({
        role: msg.role as 'user' | 'assistant' | 'system',
        content: msg.content,
      }));

      const stream = await this.client.chat.completions.create({
        model: this.model,
        messages,
        temperature: request.temperature || 0.7,
        max_tokens: request.maxTokens || 2000,
        stream: true,
      });

      for await (const chunk of stream) {
        const choice = chunk.choices[0];
        if (choice?.delta) {
          yield {
            delta: {
              content: choice.delta.content || '',
              role: choice.delta.role || 'assistant',
            },
            done: choice.finish_reason !== null,
          };
        }
      }
    } catch (error) {
      console.error('Qwen streaming error:', error);
      throw new Error(`AI streaming error: ${error instanceof Error ? error.message : 'Unknown error'}`);
    }
  }

  // Mockå“åº”æ–¹æ³•
  private getMockResponse(request: ChatRequest): ChatResponse {
    const userMessage = request.messages[request.messages.length - 1];
    const mockResponses = [
      'æ‚¨å¥½ï¼æˆ‘æ˜¯å¤–è´¸å°åŠ©æ‰‹çš„æ¼”ç¤ºç‰ˆæœ¬ã€‚ç›®å‰æ‚¨çœ‹åˆ°çš„æ˜¯æ¨¡æ‹Ÿå“åº”ï¼Œå› ä¸ºè¿˜æ²¡æœ‰é…ç½®çœŸå®çš„AI APIå¯†é’¥ã€‚\n\nå…³äºæ‚¨çš„é—®é¢˜ï¼Œæˆ‘å»ºè®®ï¼š\n\n1. ğŸ“§ **å¼€å‘ä¿¡ä¼˜åŒ–**: ä¸ªæ€§åŒ–é‚®ä»¶ä¸»é¢˜ï¼Œçªå‡ºäº§å“ä»·å€¼\n2. ğŸ¯ **å®¢æˆ·ç­›é€‰**: é‡ç‚¹å…³æ³¨æœ‰æ˜ç¡®é‡‡è´­éœ€æ±‚çš„å®¢æˆ·\n3. ğŸ“ **å¤šæ¸ é“è·Ÿè¿›**: ç»“åˆé‚®ä»¶ã€ç”µè¯ã€ç¤¾äº¤åª’ä½“\n4. ğŸ“Š **æ•°æ®åˆ†æ**: å®šæœŸåˆ†æè½¬åŒ–ç‡å’Œå®¢æˆ·åé¦ˆ\n\nå¦‚éœ€å®Œæ•´çš„AIåŠŸèƒ½ï¼Œè¯·è”ç³»ç®¡ç†å‘˜é…ç½®çœŸå®çš„é€šä¹‰åƒé—®APIå¯†é’¥ã€‚',
      
      'æ„Ÿè°¢æ‚¨çš„å’¨è¯¢ï¼ä½œä¸ºå¤–è´¸å°åŠ©æ‰‹ï¼Œæˆ‘æ¥ä¸ºæ‚¨åˆ†æä¸€ä¸‹ï¼š\n\n**å®¢æˆ·å¼€å‘ç­–ç•¥å»ºè®®ï¼š**\n\nğŸŒ **å¸‚åœºç ”ç©¶**\n- åˆ†æç›®æ ‡å¸‚åœºçš„æ–‡åŒ–èƒŒæ™¯å’Œå•†åŠ¡ä¹ æƒ¯\n- äº†è§£å½“åœ°çš„èŠ‚å‡æ—¥å’Œæœ€ä½³è”ç³»æ—¶é—´\n- ç ”ç©¶ç«äº‰å¯¹æ‰‹çš„ç­–ç•¥å’Œå®šä»·\n\nğŸ“§ **é‚®ä»¶è¥é”€**\n- é‚®ä»¶ä¸»é¢˜è¦ç®€æ´æ˜äº†ï¼Œé¿å…æ•æ„Ÿè¯æ±‡\n- å†…å®¹è¦çªå‡ºå®¢æˆ·çš„ç—›ç‚¹å’Œæ‚¨çš„è§£å†³æ–¹æ¡ˆ\n- é€‚å½“ä½¿ç”¨å®¢æˆ·çš„æœ¬åœ°è¯­è¨€é—®å€™\n\nğŸ’¼ **å…³ç³»å»ºç«‹**\n- å»ºç«‹ä¿¡ä»»éœ€è¦æ—¶é—´ï¼Œä¿æŒè€å¿ƒå’Œä¸“ä¸š\n- å®šæœŸåˆ†äº«è¡Œä¸šèµ„è®¯å’Œäº§å“æ›´æ–°\n- å‚åŠ è¡Œä¸šå±•ä¼šå’Œçº¿ä¸Šæ´»åŠ¨\n\nâš ï¸ æé†’ï¼šè¿™æ˜¯æ¼”ç¤ºæ¨¡å¼å›å¤ï¼Œå®Œæ•´åŠŸèƒ½éœ€è¦é…ç½®APIå¯†é’¥ã€‚',
      
      'æ‚¨å¥½ï¼å…³äºå¤–è´¸ä¸šåŠ¡ï¼Œæˆ‘æœ‰ä»¥ä¸‹å‡ ç‚¹å»ºè®®ï¼š\n\n**æé«˜è¯¢ç›˜è´¨é‡çš„æ–¹æ³•ï¼š**\n\nğŸ¯ **ç²¾å‡†å®šä½**\n- æ˜ç¡®ç›®æ ‡å®¢æˆ·ç”»åƒ\n- åˆ†æå®¢æˆ·çš„é‡‡è´­å‘¨æœŸ\n- å…³æ³¨å®¢æˆ·çš„å®é™…éœ€æ±‚\n\nğŸ“ˆ **æå‡è½¬åŒ–ç‡**\n- å¿«é€Ÿå“åº”å®¢æˆ·è¯¢ç›˜ï¼ˆ24å°æ—¶å†…ï¼‰\n- æä¾›è¯¦ç»†çš„äº§å“ä¿¡æ¯å’ŒæŠ¥ä»·\n- å±•ç¤ºå…¬å¸å®åŠ›å’ŒæˆåŠŸæ¡ˆä¾‹\n\nğŸ¤ **ç»´æŠ¤å®¢æˆ·å…³ç³»**\n- å»ºç«‹å®¢æˆ·æ¡£æ¡ˆï¼Œè®°å½•æ²Ÿé€šå†å²\n- èŠ‚å‡æ—¥é—®å€™å’Œå®šæœŸå›è®¿\n- æä¾›ä¼˜è´¨çš„å”®åæœåŠ¡\n\nğŸ“Š **æ•°æ®é©±åŠ¨å†³ç­–**\n- åˆ†æé‚®ä»¶å¼€å¯ç‡å’Œå›å¤ç‡\n- è·Ÿè¸ªå®¢æˆ·çš„å‚ä¸åº¦å’Œå…´è¶£åº¦\n- è°ƒæ•´ç­–ç•¥ä»¥æé«˜æ•ˆæœ\n\næ³¨ï¼šå½“å‰ä¸ºæ¼”ç¤ºæ¨¡å¼ï¼Œå®é™…ä½¿ç”¨è¯·é…ç½®çœŸå®APIã€‚'
    ];

    const randomResponse = mockResponses[Math.floor(Math.random() * mockResponses.length)];
    
    const message: AgentMessage = {
      id: crypto.randomUUID(),
      role: 'assistant',
      content: randomResponse,
      timestamp: new Date().toISOString(),
    };

    return {
      message,
      usage: {
        promptTokens: 100,
        completionTokens: 150,
        totalTokens: 250,
      },
    };
  }

  // Mockæµå¼å“åº”
  private async *getMockStreamResponse(request: ChatRequest): AsyncGenerator<any, void, unknown> {
    const response = this.getMockResponse(request);
    const content = response.message.content;
    const words = content.split('');
    
    for (let i = 0; i < words.length; i++) {
      await new Promise(resolve => setTimeout(resolve, Math.random() * 50 + 10));
      
      yield {
        delta: {
          content: words[i],
          role: 'assistant',
        },
        done: false,
      };
    }
    
    yield {
      delta: {
        content: '',
        role: 'assistant',
      },
      done: true,
    };
  }
}